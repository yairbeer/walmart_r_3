{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess test data\n",
    "trainset = pd.DataFrame.from_csv('train.csv', index_col=1)\n",
    "trainset = trainset.fillna(-999)\n",
    "trainset[['Upc', 'FinelineNumber']] = trainset[['Upc', 'FinelineNumber']].astype(str)\n",
    "n = trainset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = trainset['TripType']\n",
    "train_result = train_result.groupby(by=train_result.index, sort=False).mean()\n",
    "n_trips = train_result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_not_count = pd.get_dummies(trainset['Weekday'])\n",
    "train_data_not_count = train_data_not_count.groupby(by=train_data_not_count.index, sort=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_count_dep = pd.get_dummies(trainset['DepartmentDescription'])\n",
    "tmp_index = train_data_count_dep.index\n",
    "tmp_columns = list(train_data_count_dep.columns.values)\n",
    "tmp_table = np.array(train_data_count_dep) * np.array(trainset['ScanCount']).reshape((n, 1))\n",
    "train_data_count_dep = pd.DataFrame(tmp_table)\n",
    "train_data_count_dep.columns = tmp_columns\n",
    "train_data_count_dep.index = tmp_index\n",
    "train_data_count_dep = train_data_count_dep.groupby(by=train_data_count_dep.index, sort=False).sum()\n",
    "\n",
    "# need to separate between returned and bought goods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tot_items = trainset['ScanCount'].groupby(by=trainset.index, sort=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5501.0', '1508.0', '135.0', '808.0', '-999.0', '0.0', '9546.0', '1407.0', '4606.0', '115.0', '203.0', '100.0', '3004.0', '4010.0', '3601.0', '3600.0', '110.0', '3120.0', '3555.0', '8101.0', '5017.0', '801.0', '7010.0']\n"
     ]
    }
   ],
   "source": [
    "# find most bought FinelineNumber\n",
    "fineline_density = trainset['FinelineNumber'].value_counts()\n",
    "sparsity = n_trips * 0.02\n",
    "n_features = np.sum(fineline_density > sparsity)\n",
    "# print n_features\n",
    "fineline_density = fineline_density.iloc[:n_features]\n",
    "fineline_cols = list(fineline_density.index)\n",
    "print fineline_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove sparse FinelineNumber products\n",
    "tmp_series = np.zeros((trainset.shape[0], 1))\n",
    "for i in range(trainset.shape[0]):\n",
    "    flnumber = trainset.iloc[i]['FinelineNumber']\n",
    "    if flnumber in fineline_cols:\n",
    "        tmp_series[i] = flnumber\n",
    "trainset['FinelineNumber'] = tmp_series\n",
    "print trainset['FinelineNumber'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_data_not_count, train_data_count_dep, train_data_tot_items], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess test data\n",
    "testset = pd.DataFrame.from_csv('test.csv', index_col=0)\n",
    "test_data_not_count = pd.get_dummies(testset['Weekday'])\n",
    "test_data_not_count = test_data_not_count.groupby(by=test_data_not_count.index, sort=False).mean()\n",
    "n_test = testset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_count_dep = pd.get_dummies(testset['DepartmentDescription'])\n",
    "tmp_index = test_data_count_dep.index\n",
    "tmp_columns = list(test_data_count_dep.columns.values)\n",
    "tmp_table = np.array(test_data_count_dep) * np.array(testset['ScanCount']).reshape((n_test, 1))\n",
    "test_data_count_dep = pd.DataFrame(tmp_table)\n",
    "test_data_count_dep.columns = tmp_columns\n",
    "test_data_count_dep.index = tmp_index\n",
    "test_data_count_dep = test_data_count_dep.groupby(by=test_data_count_dep.index, sort=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tot_items = testset['ScanCount'].groupby(by=testset.index, sort=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test_data_not_count, test_data_count_dep, test_data_tot_items], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common coloumns\n",
    "col_train = list(train.columns.values)\n",
    "col_test = list(test.columns.values)\n",
    "col_common = []\n",
    "# add only common columns for train and test\n",
    "for col in col_train:\n",
    "    if col in col_test:\n",
    "        col_common.append(col)\n",
    "train = train[col_common]\n",
    "test = test[col_common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common preprocessing\n",
    "# Standardizing\n",
    "stding = StandardScaler()\n",
    "train = stding.fit_transform(train)\n",
    "test = stding.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'ix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-3b0205255246>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtrain_result_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'ix'"
     ]
    }
   ],
   "source": [
    "# # CV n = 4\n",
    "# cv_n = 4\n",
    "\n",
    "# metric = []\n",
    "# for train_index, test_index in kf:\n",
    "#     X_train, X_test = train_cv[train_index, :], train_cv[test_index, :]\n",
    "#     y_train, y_test = train_result_cv[train_index].ravel(), train_result_cv[test_index].ravel()\n",
    "#     print X_train.shape, X_test.shape\n",
    "#     print len(y_train), len(y_test )\n",
    "#     # train machine learning\n",
    "#     classifier.fit(X_train, y_train)\n",
    "\n",
    "#     # predict\n",
    "#     class_pred = classifier.predict_proba(X_test)\n",
    "\n",
    "#     # evaluate\n",
    "#     print log_loss(y_test, class_pred)\n",
    "#     metric.append(log_loss(y_test, class_pred))\n",
    "# print 'The log loss is: ', np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict testset\n",
    "classifier.fit(train, train_result)\n",
    "predicted_results = classifier.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3211670336447216"
      ]
     },
     "execution_count": 19,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "predicted_results_self = classifier.predict_proba(train)\n",
    "log_loss(train_result ,predicted_results_self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PCA\n",
    "# pcaing = PCA(n_components=2)\n",
    "# train_pca = pcaing.fit_transform(train)\n",
    "# test_pca = pcaing.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file = pd.DataFrame.from_csv(\"sample_submission.csv\")\n",
    "submission_file[list(submission_file.columns.values)] = predicted_results\n",
    "submission_file.to_csv(\"trysub_rf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}